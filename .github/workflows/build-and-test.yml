name: Run Tests, Build Python Distributions

on:
    push:
    pull_request:

defaults:
  run:
    shell: bash -l {0}

env:
  WINDOWS_PIP_CACHE: ~\AppData\Local\pip\Cache
  MACOS_PIP_CACHE: ~/Library/Caches/pip
  CONDA_CACHE: ~/conda_pkgs_dir  # setup-miniconda sets same cache dir on windows and mac

jobs:
    # This job will check for obvious syntax errors.
    # The other jobs in this file depend on this one and won't show up in the
    # jobs list on actions until this one completes successfully.
    # Best to run in linux ... windows won't honor nonzero exit statuses
    # by default.
    check-syntax-errors:
        name: "Check for syntax errors"
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v2
              with:
                  # Fetch complete history for accurate versioning
                  fetch-depth: 0

            - name: Set up python 3.9
              uses: actions/setup-python@v2
              with:
                  python-version: 3.9

            - name: Set up environment
              run: python -m pip install --upgrade pip setuptools setuptools_scm flake8

            - name: Lint with flake8
              run: |
                # stop the build if there are Python syntax errors or undefined names
                python -m flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
                # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
                python -m flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    run-model-tests:
        name: "Run model tests"
        runs-on: ${{ matrix.os }}
        needs: check-syntax-errors
        strategy:
            fail-fast: false
            max-parallel: 4
            matrix:
                python-version: [3.7, 3.8, 3.9]
                python-architecture: [x64]
                os: [windows-latest, macos-latest]
                include:
                    - python-version: 3.7
                      numpy: "numpy=1.15"  # fuzzy assertion in conda is single '='
                      gdal: "gdal==3.1.2"
                    - python-version: 3.8
                      numpy: "numpy=1.16"
                      gdal: "gdal==3.2.0"
                    - python-version: 3.9
                      numpy: "numpy=1.20"
                      gdal: "gdal==3.3.1"
                    - os: macos-latest
                      conda-prefix: /Users/runner/miniconda3/envs
                    - os: windows-latest
                      conda-prefix: C:\Miniconda3\envs
        steps:
            - uses: actions/checkout@v2
              with:
                  # Fetch complete history for accurate versioning
                  fetch-depth: 0

            # Can't use setup-python pip caching feature because it can't do
            # separate caches for different OSs and python versions
            - name: Set up python
              uses: actions/setup-python@v2
              with:
                  python-version: ${{ matrix.python-version }}

            - name: Get current week
              run: |
                echo $pythonLocation
                echo "WEEK=$(date +%U)" >> $GITHUB_ENV

            # - name: Restore pip cache (MacOS)
            #   uses: actions/cache@v2
            #   if: matrix.os == 'macos-latest'
            #   with:
            #       path: ${{ env.MACOS_PIP_CACHE }}
            #       key: pip-${{ matrix.os }}-python${{ matrix.python-version }}-model-tests-${{ env.WEEK }}

            # - name: Restore pip cache (Windows)
            #   uses: actions/cache@v2
            #   if: matrix.os == 'windows-latest'
            #   with:
            #       path: ${{ env.WINDOWS_PIP_CACHE }}
            #       key: pip-${{ matrix.os }}-python${{ matrix.python-version }}-model-tests-${{ env.WEEK}}

            # - name: Restore conda cache
            #   uses: actions/cache@v2
            #   with:
            #       path: ${{ env.CONDA_CACHE }}
            #       key: conda-${{ matrix.os }}-python${{ matrix.python-version }}-model-tests-${{ env.WEEK}}

            - name: Restore python environment cache
              uses: actions/cache@v2
              with:
                path: ${{ env.pythonLocation }}
                key: ${{ env.pythonLocation }}-model-tests-${{ env.WEEK}}

            - name: List environment contents
              run: ls $pythonLocation

            # NOTE: It takes twice as long to save the sample data cache
            # as it does to do a fresh clone (almost 5 minutes vs. 2.5 minutes)
            # Test data is way, way faster by contrast (on the order of a few
            # seconds to archive).
            - name: Restore git-LFS test data cache
              uses: actions/cache@v2
              with:
                  path: data/invest-test-data
                  key: git-lfs-testdata-${{ hashfiles('Makefile') }}

            - name: Setup conda environment
              uses: conda-incubator/setup-miniconda@v2
              with:
                  activate-environment: ${{ matrix.os }}-test-env
                  auto-update-conda: true
                  python-version: ${{ matrix.python-version }}
                  channels: conda-forge
                  use-only-tar-bz2: true # this needs to be set for caching to work properly

            - name: List environment contents
              run: |
                echo $CONDA_PREFIX
                ls $CONDA_PREFIX/bin
                conda list
                echo "CONDA_PREFIX=$CONDA_PREFIX" >> $GITHUB_ENV

            - name: Restore conda environment cache
              uses: actions/cache@v2
              with:
                path: ${{ env.CONDA_PREFIX }}
                key: ${{ matrix.os }}-${{ env.pythonLocation }}-model-tests-${{ env.WEEK }}
              id: condacache

            - name: List environment contents again
              run: |
                ls $CONDA_PREFIX
                conda list

            - name: Install build dependencies
              if: steps.condacache.outputs.cache-hit != 'true'
              shell: bash -l {0}
              run: |
                  pip cache list
                  ls ${{ env.CONDA_CACHE }}
                  conda install nomkl # make sure numpy is w/out MKL
                  conda upgrade -y pip setuptools
                  conda install ${{ matrix.numpy }} ${{ matrix.gdal }} toml twine build
                  conda install $(python -c "import toml;print(' '.join(toml.load('pyproject.toml')['build-system']['requires']))")

            - name: Build wheel
              shell: bash -l {0}
              run: |
                  python -m build --wheel
                  python -m twine check dist/*

            - name: Install runtime dependencies
              if: steps.condacache.outputs.cache-hit != 'true'
              shell: bash -l {0}
              run: |
                  python ./scripts/convert-requirements-to-conda-yml.py \
                    requirements.txt requirements-dev.txt \
                    requirements-gui.txt > requirements-all.yml
                  conda env update --file requirements-all.yml

            - name: Conda Environment Listing
              shell: bash -l {0}
              run: |
                  conda list
                  conda list --export > conda-env.txt

            - name: Download Conda Env Artifact
              continue-on-error: true
              # Using 'dawidd6' since 'download-artifact' GH action doesn't
              # support downloading artifacts from prior workflow runs
              uses: dawidd6/action-download-artifact@v2
              with:
                  workflow: build-and-test.yml
                  # Get frozen conda env artifact from last successful workflow
                  workflow_conclusion: success
                  name: Conda Env for ${{ matrix.os }} ${{ matrix.python-version }} ${{ matrix.python-architecture }}
                  path: ./conda-env-artifact

            - name: Compare Conda Environments
              continue-on-error: true
              shell: bash -l {0}
              run: |
                  diff ./conda-env.txt ./conda-env-artifact/conda-env.txt

            - name: Run model tests
              shell: bash -l {0}
              run: |
                  pip install $(find dist -name "natcap.invest*.whl")
                  make test

            - uses: actions/upload-artifact@v2
              with:
                  name: Wheel for ${{ matrix.os }} ${{ matrix.python-version }} ${{ matrix.python-architecture }}
                  path: dist

            - uses: actions/upload-artifact@v2
              with:
                  name: Conda Env for ${{ matrix.os }} ${{ matrix.python-version }} ${{ matrix.python-architecture }}
                  path: ./conda-env.txt

            - name: Authenticate GCP
              # Secrets not available in PR so don't use GCP.
              if: github.event_name != 'pull_request'
              uses: google-github-actions/auth@v0
              with:
                credentials_json: ${{ secrets.GOOGLE_SERVICE_ACC_KEY }}

            - name: Set up GCP
              if: github.event_name != 'pull_request'
              uses: google-github-actions/setup-gcloud@v0

            - name: Deploy artifacts to GCS
              # Secrets not available in PR so don't use GCP.
              if: github.event_name != 'pull_request'
              shell: bash -l {0}
              run: |
                  # Specify which python version we want to use (it's the one
                  # we're using in actions/setup-miniconda)
                  export CLOUDSDK_PYTHON=$(which python)
                  export CLOUDSDK_GSUTIL_PYTHON=$(which python)

                  # setup-gcloud action adds 'gsutil' to the PATH
                  make GSUTIL="gsutil" deploy

    test-source-distribution:
        name: "Check sdist"
        runs-on: ${{ matrix.os }}
        needs: check-syntax-errors
        strategy:
            matrix:
                python-version: [3.7, 3.8, 3.9]
                python-architecture: [x64]
                os: [windows-latest, macos-latest]
        steps:
            - uses: actions/checkout@v2

            - name: Fetch git tags
              run: git fetch origin +refs/tags/*:refs/tags/*

            - name: Set up python
              uses: actions/setup-python@v2
              with:
                  python-version: ${{ matrix.python-version }}

            - name: Get current week
              run: echo "WEEK=$(date +%U)" >> $GITHUB_ENV

            - name: Restore pip cache (MacOS)
              uses: actions/cache@v2
              if: matrix.os == 'macos-latest'
              with:
                  path: ${{ env.MACOS_PIP_CACHE }}
                  key: pip-${{ matrix.os }}-python${{ matrix.python-version }}-test-sdist-${{ env.WEEK}}

            - name: Restore pip cache (Windows)
              uses: actions/cache@v2
              if: matrix.os == 'windows-latest'
              with:
                  path: ${{ env.WINDOWS_PIP_CACHE }}
                  key: pip-${{ matrix.os }}-python${{ matrix.python-version }}-test-sdist-${{ env.WEEK}}

            - name: Restore conda cache
              uses: actions/cache@v2
              with:
                  path: ${{ env.CONDA_CACHE }}
                  key: conda-${{ matrix.os }}-python${{ matrix.python-version }}-test-sdist-${{ env.WEEK}}

            - name: Setup conda environment
              uses: conda-incubator/setup-miniconda@v2
              with:
                  activate-environment: source-env
                  auto-update-conda: true
                  python-version: ${{ matrix.python-version }}
                  channels: conda-forge
                  use-only-tar-bz2: true

            - name: Install dependencies
              shell: bash -l {0}
              run: |
                  conda install nomkl # make sure numpy is w/out MKL
                  conda upgrade -y pip setuptools
                  conda install toml twine build
                  conda install $(python -c "import toml;print(' '.join(toml.load('pyproject.toml')['build-system']['requires']))")
                  python ./scripts/convert-requirements-to-conda-yml.py \
                    requirements.txt > requirements-all.yml
                  conda env update --file requirements-all.yml

            - name: Build source distribution
              shell: bash -l {0}
              run: |
                  # Because we're using PEP518 build requirements, the user's
                  # computer is guaranteed to have cython available at build
                  # time.  Thus, it is no longer necessary to distribute the
                  # .cpp files in addition to the .pyx files.
                  python -m build --sdist
                  python -m twine check dist/*

            - name: Install from source distribution
              shell: bash -l {0}
              run : |
                  # Prevent pip from thinking that CWD is a natcap.invest
                  # installation. It's not.
                  rm -r natcap.invest.egg-info

                  # Install natcap.invest from the sdist in dist/
                  pip install $(find dist -name "natcap.invest*")

                  # Model tests should cover model functionality, we just want
                  # to be sure that we can import `natcap.invest` here.
                  # The point here is to make sure that we can build
                  # natcap.invest from source and that it imports.
                  python -c "from natcap.invest import *"

            - uses: actions/upload-artifact@v2
              with:
                  name: Source distribution
                  path: dist

            - name: Authenticate GCP
              # Secrets not available in PR so don't use GCP.
              if: github.event_name != 'pull_request'
              uses: google-github-actions/auth@v0
              with:
                credentials_json: ${{ secrets.GOOGLE_SERVICE_ACC_KEY }}

            - name: Set up GCP
              if: github.event_name != 'pull_request'
              uses: google-github-actions/setup-gcloud@v0

            - name: Deploy artifacts to GCS
              # Secrets not available in PR so don't use GCP.
              # Only upload sdist in one of the matrix cases so we don't
              # overwrite artifacts or have duplicates (mac/windows sdists have
              # different extensions)
              if: github.event_name != 'pull_request' && matrix.os == 'macos-latest' && matrix.python-version == '3.7'
              shell: bash -l {0}
              run: |
                  # Specify which python version we want to use (it's the one
                  # we're using in actions/setup-miniconda)
                  export CLOUDSDK_PYTHON=$(which python)
                  export CLOUDSDK_GSUTIL_PYTHON=$(which python)

                  # setup-gcloud action adds 'gsutil' to the PATH
                  make GSUTIL="gsutil" deploy

    validate-resources:
        name: "Validate Sampledata & User Guide"
        runs-on: windows-latest
        needs: check-syntax-errors
        steps:
            - uses: actions/checkout@v2
              with:
                  # Fetch complete history for accurate versioning
                  fetch-depth: 0

            - name: Set up python
              uses: actions/setup-python@v2
              with:
                  python-version: 3.9

            - name: Get current week
              run: |
                echo ${{ env.pythonLocation }}
                echo "WEEK=$(date +%U)" >> $GITHUB_ENV

            - name: Restore pip cache
              uses: actions/cache@v2
              with:
                  path: ${{ env.WINDOWS_PIP_CACHE }}
                  key: pip-validate-resources-${{ env.WEEK}}

            - name: Restore conda cache
              uses: actions/cache@v2
              with:
                  path: ${{ env.CONDA_CACHE }}
                  key: conda-validate-resources-${{ env.WEEK}}

            - name: Setup conda environment
              uses: conda-incubator/setup-miniconda@v2
              with:
                  activate-environment: validate-env
                  auto-update-conda: true
                  python-version: 3.9
                  channels: conda-forge
                  use-only-tar-bz2: true

            - name: Install dependencies
              shell: bash -l {0}
              run: |
                  conda install nomkl # make sure numpy w/out mkl
                  conda install pytest requests build
                  conda install $(python -c "import toml;print(' '.join(toml.load('pyproject.toml')['build-system']['requires']))")
                  conda upgrade -y pip wheel
                  python ./scripts/convert-requirements-to-conda-yml.py requirements.txt > requirements.yml
                  conda env update --file requirements.yml
                  make install

            - name: Validate sample data
              shell: bash -l {0}
              run: make validate_sampledata

            - name: Validate user guide links
              shell: bash -l {0}
              run: make validate_userguide_filenames

    run-ui-tests:
        name: "Run UI Tests"
        runs-on: ${{ matrix.os }}
        needs: check-syntax-errors
        strategy:
            fail-fast: False
            max-parallel: 4
            matrix:
                python-version: [3.7, 3.8, 3.9]
                python-architecture: [x64]
                os: [windows-latest]

        steps:
            - uses: actions/checkout@v2
              with:
                  # Fetch complete history for accurate versioning
                  fetch-depth: 0

            - name: Set up python
              uses: actions/setup-python@v2
              with:
                  python-version: ${{ matrix.python-version }}

            - name: Get current week
              run: echo "WEEK=$(date +%U)" >> $GITHUB_ENV

            - name: Restore pip cache
              uses: actions/cache@v2
              with:
                  path: ${{ env.WINDOWS_PIP_CACHE }}
                  key: pip-${{ matrix.os }}-python${{ matrix.python-version }}-ui-tests-${{ env.WEEK}}

            - name: Restore conda cache
              uses: actions/cache@v2
              with:
                  path: ${{ env.CONDA_CACHE }}
                  key: conda-${{ matrix.os }}-python${{ matrix.python-version }}-ui-tests-${{ env.WEEK}}

            - name: Restore git-LFS test data cache
              uses: actions/cache@v2
              with:
                  path: data/invest-test-data
                  key: git-lfs-testdata-${{ hashfiles('Makefile') }}

            - name: Setup conda environment
              uses: conda-incubator/setup-miniconda@v2
              with:
                  activate-environment: ui-env
                  auto-update-conda: true
                  python-version: ${{ matrix.python-version }}
                  channels: conda-forge
                  use-only-tar-bz2: true

            - name: Install dependencies
              shell: bash -l {0}
              run: |
                  conda install nomkl  # make sure numpy w/out mkl
                  conda install requests
                  conda upgrade -y pip setuptools
                  python ./scripts/convert-requirements-to-conda-yml.py \
                    requirements.txt requirements-dev.txt \
                    requirements-gui.txt > requirements-all.yml
                  conda env update --file requirements-all.yml
                  python -m pip install .

            - name: Run UI tests
              shell: bash -l {0}
              timeout-minutes: 10  # tests usually take < 2 minutes, so 10 is generous.
              run: make test_ui
